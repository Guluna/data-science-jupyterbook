{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62248bc8",
   "metadata": {},
   "source": [
    "# Chapter 5- Hypothesis Testing in Python\n",
    "\n",
    "## Hypothesis Testing\n",
    "\n",
    "It is nothing more than a test (or an educated guess) to decide whether an assumption is correct or not. We'll focus on the T-test, a way to tell if two groups are different.\n",
    "\n",
    "## What is Hypothesis Testing?\n",
    "\n",
    "Hypothesis Testing is like making an educated guess about a situation. For instance, \"students at School X study for 2 hours every day.\" We then gather information to see if this guess holds true or not.\n",
    "- Null Hypothesis (H0): The statement weâ€™re questioning. For example, \"students at School X do not study for 2 hours every day.\"\n",
    "- Alternative Hypothesis (HA): The statement we want to support. For example, \"students at School X study for 2 hours every day.\"\n",
    "\n",
    "It's like a courtroom trial where the null hypothesis is being tested, and the alternative hypothesis presents the evidence against the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f847f6ee",
   "metadata": {},
   "source": [
    "## T-test(s):\n",
    "\n",
    "T-test checks if the two groups' mean values are truly different. \n",
    "\n",
    "- One-sample T-test: \"Does this coffee look like it came from a pot that averages 70 degrees?\"\n",
    "- Two-sample T-test: \"Are men's and women's average weights different?\"\n",
    "- Paired-sample T-test: \"Did people's average stress levels change after using a meditation app for a month?\"\n",
    "\n",
    "T-test gives us two values: the t-statistic and the p-value. The bigger the t-statistic, the more difference there is between groups mean values. The p-value is the probability in favor of null hypothesis (i.e. probability that Null hypothesis is true given the data). If the p-value is less than 0.05, usually, we conclude that the difference is statistically significant and not due to randomness and thus it is safe to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010c2b38",
   "metadata": {},
   "source": [
    "### For One Sample T-test, \n",
    "- Null hypothesis is that the mean age of users (provided as the ages array) equals 30\n",
    "- Alternative hypothesis states that the mean age is not 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15df2453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -1.7405028310295299\n",
      "p-value: 0.11239328363861013\n",
      "t-statistic: 3.86215700410574\n",
      "p-value: 0.00021283871266502\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# One Sample T-Test\n",
    "ages = np.array([25, 33, 26, 25, 27, 27, 27, 29, 30, 31, 33])  # mean = 28.45\n",
    "t_statistic, p_value = stats.ttest_1samp(ages, 30)\n",
    "print(\"t-statistic:\", t_statistic)  # -1.74\n",
    "print(\"p-value:\", p_value)  # 0.1124 so we don't have enough statistical evidence to claim that the mean age of users is different from 30\n",
    "\n",
    "\n",
    "ages = np.random.normal(loc=33, scale=5, size=90)  # mean = 33\n",
    "t_statistic, p_value = stats.ttest_1samp(ages, 30)\n",
    "print(\"t-statistic:\", t_statistic)  # 4.872\n",
    "print(\"p-value:\", p_value)  # ~0.000 so we reject the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cc0246",
   "metadata": {},
   "source": [
    "### For a Two Sample T-Test\n",
    "\n",
    "Imagine you want to test if two teams in your office work the same hours. After collecting data, you can use a two-sample T-test to find out.\n",
    "\n",
    "- The null hypothesis is that the mean working hours of Team A is equal to the mean working hours of Team B.\n",
    "- The alternative hypothesis is that the mean working hours of Team A is different from the mean working hours of Team B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa339086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Management hours mean: 2.75\n",
      "Developer hours mean: 2.1875\n",
      "t-statistic: 2.6790325100441423\n",
      "p-value: 0.017979525890164865\n",
      "We reject the null hypothesis. There is a significant difference in meeting hours.\n"
     ]
    }
   ],
   "source": [
    "# Assuming meeting hours for management and developer team before and after new project planning implementation\n",
    "management_hours = np.array([3, 2, 3, 3, 3, 2, 3, 3])\n",
    "developer_hours = np.array([2, 2, 2, 2, 3, 2, 2.5, 2])\n",
    "print(\"Management hours mean:\", management_hours.mean())\n",
    "print(\"Developer hours mean:\", developer_hours.mean())\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(management_hours, developer_hours)\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "significance_level = 0.05\n",
    "if p_value < significance_level:\n",
    "    print(\"We reject the null hypothesis. There is a significant difference in meeting hours.\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis. There is no significant difference in meeting hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e1077",
   "metadata": {},
   "source": [
    "## Mann-Whitney U test\n",
    "\n",
    "This tool helps determine if two datasets are (significantly) different when data doesn't meet the normality assumption for T-tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34a45b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-value: 60.0\n",
      "p-value: 0.4699923731723571\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Data on time spent (in minutes) on the website by users\n",
    "time_A = np.array([31, 22, 39, 27, 35, 28, 34, 26, 23, 33])\n",
    "time_B = np.array([26, 25, 30, 28, 29, 28, 27, 30, 27, 28])\n",
    "\n",
    "# Perform the Mann-Whitney U test\n",
    "U, p = mannwhitneyu(time_A, time_B)\n",
    "\n",
    "# Print out the results\n",
    "print(f'U-value: {U}')  # 60\n",
    "print(f'p-value: {p}')  # 0.47 thus we fail to reject the null hypothesis and conclude that there isn't a significant different between the two groups "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48c70a5",
   "metadata": {},
   "source": [
    "## ANOVA\n",
    "\n",
    "Analysis of Variance or ANOVA is a way to determine if there are significant differences between the **means (or averages) of three or more groups**.\n",
    "\n",
    "ANOVA assumes three things:\n",
    "- Normality: The data from each group looks like a normal distribution.\n",
    "- Homogeneity of Variance: Each group has the same spread or variance.\n",
    "- Independence: Each data point doesn't depend on the others.\n",
    "\n",
    "### One-way ANOVA\n",
    "Think of One-way ANOVA like a game where you're comparing the average scores (means) of several teams (groups). The ultimate goal is to figure out if there is at least one team scoring differently than the others.\n",
    "\n",
    "The output of the One-way ANOVA test is a value called F-statistic. A simple way to think about the F-statistic is like a signal-to-noise ratio:\n",
    "\n",
    "    Signal: How much the group means differ from each other.\n",
    "    Noise: How much the group members differ among themselves.\n",
    "\n",
    "If the teams' scores are all similar, we would have a low signal and high noise, yielding an F-statistic close to 1.0. But if one of the teams' average score is substantially different from the others, the signal increases compared to the noise, resulting in an F-statistic greater than 1.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78301b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-value: 7.845172641301955\n",
      "P-value: 0.006623953105761937\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample weights for 3 different apple types\n",
    "data = pd.DataFrame({\n",
    "    'apple_type': ['Apple1']*5 + ['Apple2']*5 + ['Apple3']*5,\n",
    "    'weight': [162.5, 165.0, 167.5, 160.0, 158.5, 175.0, 177.5, 172.5, 170.0, 160.5, 182.5, 185.0, 180.0, 177.5, 165.5]\n",
    "})\n",
    "\n",
    "# Select weights for each apple type\n",
    "apple1_weights = data['weight'][data['apple_type'] == 'Apple1']\n",
    "apple2_weights = data['weight'][data['apple_type'] == 'Apple2']\n",
    "apple3_weights = data['weight'][data['apple_type'] == 'Apple3']\n",
    "\n",
    "from scipy import stats\n",
    "# Perform One-way ANOVA\n",
    "f_value, p_value = stats.f_oneway(apple1_weights, \n",
    "                                  apple2_weights, \n",
    "                                  apple3_weights)\n",
    "\n",
    "# Print the F-value and P-value\n",
    "print(\"F-value:\", f_value)  # 7.845\n",
    "print(\"P-value:\", p_value)  # 0.006 thus we can confidently reject the idea that all apple types have the same average weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf20d26",
   "metadata": {},
   "source": [
    "## Chi-Square\n",
    "\n",
    "It's a handy tool for assessing whether there are **significant differences between observed and expected frequencies in one or more categories**.\n",
    "\n",
    "The Chi-Square Test assumes two things:\n",
    "- Randomness: The data was randomly sampled.\n",
    "- Adequacy: Each cell in the table contains at least five items, ensuring the test's validity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b72e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Statistic: 12.5\n",
      "P-value: 0.013995792487650894\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Observations\n",
    "data = pd.DataFrame({\n",
    "    'Color': ['Red', 'Blue', 'Green', 'Yellow', 'Purple'],\n",
    "    'Observed': [30, 20, 15, 10, 25],\n",
    "    'Expected': [20, 20, 20, 20, 20]\n",
    "})\n",
    "\n",
    "# Prepare observed and expected frequencies\n",
    "observed_frequencies = data['Observed']\n",
    "expected_frequencies = data['Expected']\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Perform Chi-Square Test\n",
    "chi_square_stat, p_value = stats.chisquare(observed_frequencies,\n",
    "                                           expected_frequencies)\n",
    "\n",
    "# Print the chi-square statistic and P-value\n",
    "print(\"Chi-Square Statistic:\", chi_square_stat)  # 12.5\n",
    "print(\"P-value:\", p_value)  # 0.014 suggesting that our observed marble distribution is statistically different from what we expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupybook_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}