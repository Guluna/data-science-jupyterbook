{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e36d0090",
   "metadata": {},
   "source": [
    "# Chapter 4- Code Optimization\n",
    "\n",
    "## Code Optimization Techniques in Numpy and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012d226",
   "metadata": {},
   "source": [
    "Numpy's ability to perform operations on an entire array is based on a concept called vectorization, a powerful tool that substantially increases performance. Let's demonstrate with a simple example that shows the speed difference between using Python's native function and a NumPy's vectorized function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e9750",
   "metadata": {},
   "source": [
    "## Using Numpy vs Python functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f09958b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy sum: 500189.0839013288\n",
      "Time to calculate the sum in a Numpy list: 0.0003769397735595703\n",
      "Built-in list sum 500189.0839012991\n",
      "Time to calculate the sum in a Python list: 0.04026198387145996\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Define a large array\n",
    "large_array = np.random.rand(10**6)\n",
    "\n",
    "# Numpy way\n",
    "start = time.time()\n",
    "print(\"Numpy sum:\", np.sum(large_array))  # This calculates the sum using Numpy's vectorized function\n",
    "print(\"Time to calculate the sum in a Numpy list:\", time.time() - start)\n",
    "\n",
    "# Python way of summing elements in an array\n",
    "start = time.time()\n",
    "print(\"Built-in list sum\", sum(large_array))  # This calculates the sum using Python's built-in function\n",
    "print(\"Time to calculate the sum in a Python list:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25510c1a",
   "metadata": {},
   "source": [
    "## Pandas Optimization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53088353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  target  \n",
      "0    -122.23   4.526  \n",
      "1    -122.22   3.585  \n",
      "2    -122.24   3.521  \n",
      "3    -122.25   3.413  \n",
      "4    -122.25   3.422  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   MedInc      20640 non-null  float64\n",
      " 1   HouseAge    20640 non-null  float64\n",
      " 2   AveRooms    20640 non-null  float64\n",
      " 3   AveBedrms   20640 non-null  float64\n",
      " 4   Population  20640 non-null  float64\n",
      " 5   AveOccup    20640 non-null  float64\n",
      " 6   Latitude    20640 non-null  float64\n",
      " 7   Longitude   20640 non-null  float64\n",
      " 8   target      20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "# Load the California Housing dataset\n",
    "california = datasets.fetch_california_housing()\n",
    "df = pd.DataFrame(data=np.c_[california['data'], california['target']], columns=california['feature_names'] + ['target'])\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6d93fb",
   "metadata": {},
   "source": [
    "### Choosing pd.Categorical data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4206b7b",
   "metadata": {},
   "source": [
    "Choosing the pd.Categorical data type (or use .astype('category')) specifically for categorical data (data that takes on a limited, usually fixed, number of possible values), can yield significant savings in memory. Data types like integers and floats take up more memory space than categorical data types, which can significantly reduce memory usage, especially for large datasets. For high-cardinality columns (columns with many thousands of unique values), transforming them into a 'category' type can make operations like grouping much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03ba8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MedInc'] = df['MedInc'].astype('category')\n",
    "\n",
    "# California Housing dataset does not have any Categorical features so next line of code won't work\n",
    "# df['Type'] = pd.Categorical(df['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f8347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   MedInc      20640 non-null  category\n",
      " 1   HouseAge    20640 non-null  float64 \n",
      " 2   AveRooms    20640 non-null  float64 \n",
      " 3   AveBedrms   20640 non-null  float64 \n",
      " 4   Population  20640 non-null  float64 \n",
      " 5   AveOccup    20640 non-null  float64 \n",
      " 6   Latitude    20640 non-null  float64 \n",
      " 7   Longitude   20640 non-null  float64 \n",
      " 8   target      20640 non-null  float64 \n",
      "dtypes: category(1), float64(8)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bef3fc",
   "metadata": {},
   "source": [
    "### Downcasting Numerical Columns\n",
    "\n",
    "Another way is to reduce memory usage for cases where DataFrame features are not categorical. In Pandas, downcast is a parameter to downcast data types of Dataframe. It's used with pd.to_numeric() function to downcast data types of numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5cd39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downcast data type for 'AveBedrms' column\n",
    "df['AveBedrms'] = pd.to_numeric(df['AveBedrms'], downcast='float')\n",
    "df['Population'] = df['Population'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ee7b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   MedInc      20640 non-null  category\n",
      " 1   HouseAge    20640 non-null  float64 \n",
      " 2   AveRooms    20640 non-null  float64 \n",
      " 3   AveBedrms   20640 non-null  float32 \n",
      " 4   Population  20640 non-null  int32   \n",
      " 5   AveOccup    20640 non-null  float64 \n",
      " 6   Latitude    20640 non-null  float64 \n",
      " 7   Longitude   20640 non-null  float64 \n",
      " 8   target      20640 non-null  float64 \n",
      "dtypes: category(1), float32(1), float64(6), int32(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c9649a",
   "metadata": {},
   "source": [
    "### Method Chaining (& in-place = True)\n",
    "\n",
    "Another valuable asset is method chaining, which combines several operations into one unified code line, improving execution speed and enhancing code readability.\n",
    "\n",
    "Also, it is worth noting that the inplace parameter in Pandas operations deserves mention because it is more memory-friendly. It applies changes directly to your DataFrame instead of creating an entirely new frame for the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f5604a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/1x3pcpw96cn3pc3l3hqztlvr0000gn/T/ipykernel_18860/960668732.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_copy.dropna(inplace=True)\n",
      "/var/folders/ll/1x3pcpw96cn3pc3l3hqztlvr0000gn/T/ipykernel_18860/960668732.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[df['Population'] > 1000].dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Regular way\n",
    "df_copy = df[df['Population'] > 1000]\n",
    "df_copy.dropna(inplace=True)\n",
    "\n",
    "# Optimized way\n",
    "df[df['Population'] > 1000].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e695a3e8",
   "metadata": {},
   "source": [
    "### Practical Example of Efficient Memory Utilization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7adac9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original memory usage: 1.4173622131347656 MB\n",
      "Optimized memory usage: 1.2598915100097656 MB\n",
      "Memory saved: 0.157470703125 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "# Load the California Housing dataset\n",
    "california = datasets.fetch_california_housing()\n",
    "df = pd.DataFrame(data=np.c_[california['data'], california['target']], columns=california['feature_names'] + ['target'])\n",
    "\n",
    "def memory_usage_pandas(df):\n",
    "    bytes = df.memory_usage(deep=True).sum()\n",
    "    return bytes / 1024**2  # Convert bytes to megabytes\n",
    "\n",
    "original_memory = memory_usage_pandas(df)\n",
    "\n",
    "# Optimize memory usage in Pandas using categorical data types\n",
    "# California Housing dataset does not have any Categorical features, so we will use downcasting\n",
    "df['AveBedrms'] = pd.to_numeric(df['AveBedrms'], downcast='float')\n",
    "df['AveRooms'] = pd.to_numeric(df['AveRooms'], downcast='float')\n",
    "optimized_memory = memory_usage_pandas(df)\n",
    "\n",
    "print(f'Original memory usage: {original_memory} MB')\n",
    "print(f'Optimized memory usage: {optimized_memory} MB')\n",
    "print(f'Memory saved: {original_memory - optimized_memory} MB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupybook_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}